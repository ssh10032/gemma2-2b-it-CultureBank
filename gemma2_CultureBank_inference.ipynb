{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import Dataset, load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline, TrainingArguments\n",
    "import pandas as pd\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PeftModel,\n",
    "    prepare_model_for_kbit_training,\n",
    "    get_peft_model,\n",
    ")\n",
    "from trl import SFTTrainer, setup_chat_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cc27d91a6fc4fabba356c354492b74a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, concatenate_datasets\n",
    "dataset = load_dataset(\"SALT-NLP/CultureBank\")\n",
    "\n",
    "combined_dataset  = concatenate_datasets([dataset['tiktok'], dataset['reddit']])\n",
    "train_test_split = combined_dataset.train_test_split(test_size=0.2)\n",
    "train_data = train_test_split['train']\n",
    "test_data = train_test_split['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39b70ee0b28c41e481ca32c82f2ca33a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BASE_MODEL = \"google/gemma-2-2b-it\"\n",
    "FINETUNE_MODEL = \"./gemma2-2b-it-CultureBank\"\n",
    "\n",
    "finetune_model = AutoModelForCausalLM.from_pretrained(FINETUNE_MODEL, device_map=\"auto\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, add_special_tokens=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_finetuned = pipeline(\"text-generation\", model=finetune_model, tokenizer=tokenizer, max_new_tokens=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_to_gemma2_prompt_inference(data):\n",
    "    # 시스템 메시지 포함 없이 사용자 질문 생성\n",
    "    user_message = (\n",
    "        f\"{data['eval_question']}\"\n",
    "    )\n",
    "\n",
    "    # 최종 프롬프트 형식\n",
    "    gemma2_prompt = [\n",
    "        {\"role\": \"user\", \"content\": user_message},\n",
    "    ]\n",
    "\n",
    "    # 프롬프트를 템플릿으로 적용\n",
    "    prompt = pipe_finetuned.tokenizer.apply_chat_template(gemma2_prompt, tokenize=False, add_generation_prompt=True)\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos><start_of_turn>user\n",
      "I've been invited to a friend's wedding in Utah and I've heard that it's a big deal in their community. I want to be a supportive guest, but I'm not really familiar with their traditions. Could you give me some tips on what to expect and how to be a respectful guest during the ceremony? I've heard that they place a lot of importance on spiritual union, so I'm really curious about what that means in their context.<end_of_turn>\n",
      "<start_of_turn>model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "messages = format_to_gemma2_prompt_inference(test_data[0])\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos><start_of_turn>user\n",
      "I've been invited to a friend's wedding in Utah and I've heard that it's a big deal in their community. I want to be a supportive guest, but I'm not really familiar with their traditions. Could you give me some tips on what to expect and how to be a respectful guest during the ceremony? I've heard that they place a lot of importance on spiritual union, so I'm really curious about what that means in their context.<end_of_turn>\n",
      "<start_of_turn>model\n",
      "In Utah, during weddings, it is customary for people to engage in spiritual union ceremonies, which involve the use of rings and the presence of spiritual leaders. These ceremonies are deeply rooted in the cultural and religious practices of the community, reflecting the significance of spiritual union in their traditions. The use of rings and the involvement of spiritual leaders are integral parts of these ceremonies, emphasizing the importance of spiritual connection and guidance in the union. This practice is widely regarded as a normative and standard part of the wedding customs within the sampled population, reflecting the strong cultural and religious influence on the community's wedding traditions. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = pipe_finetuned(\n",
    "    messages,\n",
    "    do_sample=True,\n",
    "    temperature=0.2,\n",
    "    top_k=50,\n",
    "    top_p=0.95,\n",
    "    add_special_tokens=True\n",
    ")\n",
    "# print(outputs[0][\"generated_text\"][len(prompt):])\n",
    "print(outputs[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt3 = [\n",
    "    {\"role\": \"user\", \n",
    "    \"content\": \"Tell me about Korea food culture\"},\n",
    "]\n",
    "prompt3 = pipe_finetuned.tokenizer.apply_chat_template(prompt3, tokenize=False, add_generation_prompt=True)\n",
    "print(prompt3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = pipe_finetuned(\n",
    "    prompt3,\n",
    "    do_sample=True,\n",
    "    temperature=0.2,\n",
    "    top_k=50,\n",
    "    top_p=0.95,\n",
    "    add_special_tokens=True\n",
    ")\n",
    "# print(outputs[0][\"generated_text\"][len(prompt):])\n",
    "print(outputs[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt4 = [\n",
    "    {\"role\": \"user\", \n",
    "    \"content\": \"I will visit Korea. Is there anything to know before visiting like public etiquette?\"},\n",
    "]\n",
    "prompt4 = pipe_finetuned.tokenizer.apply_chat_template(prompt4, tokenize=False, add_generation_prompt=True)\n",
    "print(prompt4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = pipe_finetuned(\n",
    "    prompt4,\n",
    "    do_sample=True,\n",
    "    temperature=0.2,\n",
    "    top_k=50,\n",
    "    top_p=0.95,\n",
    "    add_special_tokens=True\n",
    ")\n",
    "# print(outputs[0][\"generated_text\"][len(prompt):])\n",
    "print(outputs[0][\"generated_text\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('gemma3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e3f60f845e8f707895ee6aa709f4e24135190696373ef948e994eae5117196d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
